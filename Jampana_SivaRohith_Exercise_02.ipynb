{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivarohith99/SivaRohith_INFO5731_Fall2024/blob/main/Jampana_SivaRohith_Exercise_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ],
      "metadata": {
        "id": "FBKvD6O_TY6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your answer here\n",
        "'''How does the public sentiment towards artificial intelligence (AI) evolve over time in major news outlets?\n",
        "\n",
        "Data Needed:\n",
        "To answer this question, you would need the following types of data:\n",
        "\n",
        "News Articles:\n",
        "Title, content, publication date, author, and source (news outlet).\n",
        "Articles specifically focused on artificial intelligence (AI), its technologies, ethics, impact on society, and industries.\n",
        "Metadata:\n",
        "Date of publication.\n",
        "Article source - Times of India.\n",
        "Sentiment (positive, negative, or neutral) derived from text analysis.\n",
        "Keyword frequency (mentions of terms like \"AI,\" \"ethics,\" \"machine learning,\" \"automation\").\n",
        "Amount of Data Needed:\n",
        "Time Span: To track sentiment over time, collecting data over at least one year would be ideal. You could begin with a span of 6 months if shorter time frames are needed.\n",
        "Volume: Aim for a dataset of 500 to 1000 articles initially to cover diverse opinions and events. You can scale up later if needed.\n",
        "Sources: Collect data from major news outlet to ensure variety in perspectives (e.g., The Guardian, BBC, New York Times, Forbes, and Wired).\n",
        "Detailed Steps for Collecting and Saving the Data:\n",
        "Identify Data Sources:\n",
        "\n",
        "Choose reliable news websites that cover a wide range of articles on AI.\n",
        "Each site should have accessible news sections or search pages with relevant keywords like \"Artificial Intelligence,\" \"AI,\" or related terms.\n",
        "Set Up a Web Scraping Framework:\n",
        "\n",
        "Use Python libraries such as BeautifulSoup (for parsing HTML), Selenium (for dynamic content), or Scrapy (for advanced crawling).\n",
        "You may also use requests for simple HTTP requests to access static content.\n",
        "Search News Articles by Keywords:\n",
        "\n",
        "For each website, create a list of URLs for news articles. This can be done by querying search forms for terms like \"AI\" and setting a date filter to cover the desired time span.\n",
        "Example: The Guardian's search results for \"Artificial Intelligence.\"\n",
        "Extract Data:\n",
        "\n",
        "Use BeautifulSoup to extract relevant HTML tags, such as <title>, <date>, and <article>.\n",
        "Scrape data points like the headline, author, publication date, and article text.'''"
      ],
      "metadata": {
        "id": "cikVKDXdTbzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ],
      "metadata": {
        "id": "E9RqrlwdTfvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your answer here\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Define the base URL and search query parameters\n",
        "base_url = 'https://timesofindia.indiatimes.com/'\n",
        "search_query = 'artificial intelligence'\n",
        "total_articles = 1000\n",
        "articles_collected = 0\n",
        "article_list = []\n",
        "\n",
        "# Keywords to track\n",
        "keywords = ['AI', 'ethics', 'machine learning', 'automation']\n",
        "\n",
        "def fetch_article_links(search_url, num_pages):\n",
        "    article_links = []\n",
        "    for page in range(1, num_pages + 1):\n",
        "        params = {'q': search_query, 'page': page}\n",
        "        response = requests.get(search_url, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Find article links (modify selector based on actual site)\n",
        "            links = soup.find_all('a', href=True)\n",
        "            for link in links:\n",
        "                href = link['href']\n",
        "                if 'article' in href:\n",
        "                    full_url = href if href.startswith('http') else f\"https://timesofindia.indiatimes.com{href}\"\n",
        "                    article_links.append(full_url)\n",
        "        else:\n",
        "            print(f\"Failed to retrieve page {page}. Status code: {response.status_code}\")\n",
        "\n",
        "    return article_links\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"Returns sentiment polarity: positive, negative, or neutral\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return 'positive'\n",
        "    elif polarity < 0:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "def count_keywords(text, keywords):\n",
        "    \"\"\"Returns a dictionary of keyword frequencies in the text\"\"\"\n",
        "    word_list = text.lower().split()\n",
        "    word_counts = Counter(word_list)\n",
        "    keyword_counts = {keyword: word_counts.get(keyword.lower(), 0) for keyword in keywords}\n",
        "    return keyword_counts\n",
        "\n",
        "def scrape_article(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Extract article details (modify selectors based on actual site)\n",
        "            title = soup.find('h1').get_text() if soup.find('h1') else 'No Title'\n",
        "            date = soup.find('time')['datetime'] if soup.find('time') else 'No Date'\n",
        "            content = soup.find('div', class_='article-body').get_text() if soup.find('div', class_='article-body') else 'No Content'\n",
        "\n",
        "            # Perform sentiment analysis and keyword frequency analysis\n",
        "            sentiment = analyze_sentiment(content)\n",
        "            keyword_freq = count_keywords(content, keywords)\n",
        "\n",
        "            return {'title': title, 'date': date, 'content': content, 'url': url, 'sentiment': sentiment, **keyword_freq}\n",
        "        else:\n",
        "            print(f\"Failed to retrieve article at {url}. Status code: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching article {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    global articles_collected\n",
        "    num_pages = 10  # Number of search result pages to scrape\n",
        "\n",
        "    print(\"Fetching article links...\")\n",
        "    article_links = fetch_article_links(base_url, num_pages)\n",
        "    print(f\"Found {len(article_links)} article links.\")\n",
        "\n",
        "    print(\"Scraping articles...\")\n",
        "    for link in article_links:\n",
        "        if articles_collected >= total_articles:\n",
        "            break\n",
        "\n",
        "        article = scrape_article(link)\n",
        "        if article:\n",
        "            article_list.append(article)\n",
        "            articles_collected += 1\n",
        "            print(f\"Collected {articles_collected}/{total_articles} articles\")\n",
        "\n",
        "        time.sleep(1)  # Be respectful and avoid overwhelming the server\n",
        "\n",
        "    print(\"Saving data...\")\n",
        "    df = pd.DataFrame(article_list)\n",
        "    df.to_csv('ai_news_articles.csv', index=False)\n",
        "    print(f\"Data saved to ai_news_articles.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "4XvRknixTh1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6673df94-2aa8-46fc-fa2e-eb81557be8fa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching article links...\n",
            "Found 2330 article links.\n",
            "Scraping articles...\n",
            "Collected 1/1000 articles\n",
            "Collected 2/1000 articles\n",
            "Collected 3/1000 articles\n",
            "Collected 4/1000 articles\n",
            "Collected 5/1000 articles\n",
            "Collected 6/1000 articles\n",
            "Collected 7/1000 articles\n",
            "Collected 8/1000 articles\n",
            "Collected 9/1000 articles\n",
            "Collected 10/1000 articles\n",
            "Collected 11/1000 articles\n",
            "Collected 12/1000 articles\n",
            "Collected 13/1000 articles\n",
            "Collected 14/1000 articles\n",
            "Collected 15/1000 articles\n",
            "Collected 16/1000 articles\n",
            "Collected 17/1000 articles\n",
            "Collected 18/1000 articles\n",
            "Collected 19/1000 articles\n",
            "Collected 20/1000 articles\n",
            "Collected 21/1000 articles\n",
            "Collected 22/1000 articles\n",
            "Collected 23/1000 articles\n",
            "Collected 24/1000 articles\n",
            "Collected 25/1000 articles\n",
            "Collected 26/1000 articles\n",
            "Collected 27/1000 articles\n",
            "Collected 28/1000 articles\n",
            "Collected 29/1000 articles\n",
            "Collected 30/1000 articles\n",
            "Collected 31/1000 articles\n",
            "Collected 32/1000 articles\n",
            "Collected 33/1000 articles\n",
            "Collected 34/1000 articles\n",
            "Collected 35/1000 articles\n",
            "Collected 36/1000 articles\n",
            "Collected 37/1000 articles\n",
            "Collected 38/1000 articles\n",
            "Collected 39/1000 articles\n",
            "Collected 40/1000 articles\n",
            "Collected 41/1000 articles\n",
            "Collected 42/1000 articles\n",
            "Collected 43/1000 articles\n",
            "Collected 44/1000 articles\n",
            "Collected 45/1000 articles\n",
            "Collected 46/1000 articles\n",
            "Collected 47/1000 articles\n",
            "Collected 48/1000 articles\n",
            "Collected 49/1000 articles\n",
            "Collected 50/1000 articles\n",
            "Collected 51/1000 articles\n",
            "Collected 52/1000 articles\n",
            "Collected 53/1000 articles\n",
            "Collected 54/1000 articles\n",
            "Collected 55/1000 articles\n",
            "Collected 56/1000 articles\n",
            "Collected 57/1000 articles\n",
            "Collected 58/1000 articles\n",
            "Collected 59/1000 articles\n",
            "Collected 60/1000 articles\n",
            "Collected 61/1000 articles\n",
            "Collected 62/1000 articles\n",
            "Collected 63/1000 articles\n",
            "Collected 64/1000 articles\n",
            "Collected 65/1000 articles\n",
            "Collected 66/1000 articles\n",
            "Collected 67/1000 articles\n",
            "Collected 68/1000 articles\n",
            "Collected 69/1000 articles\n",
            "Collected 70/1000 articles\n",
            "Collected 71/1000 articles\n",
            "Collected 72/1000 articles\n",
            "Collected 73/1000 articles\n",
            "Collected 74/1000 articles\n",
            "Collected 75/1000 articles\n",
            "Collected 76/1000 articles\n",
            "Collected 77/1000 articles\n",
            "Collected 78/1000 articles\n",
            "Collected 79/1000 articles\n",
            "Collected 80/1000 articles\n",
            "Collected 81/1000 articles\n",
            "Collected 82/1000 articles\n",
            "Collected 83/1000 articles\n",
            "Collected 84/1000 articles\n",
            "Collected 85/1000 articles\n",
            "Collected 86/1000 articles\n",
            "Collected 87/1000 articles\n",
            "Collected 88/1000 articles\n",
            "Collected 89/1000 articles\n",
            "Collected 90/1000 articles\n",
            "Collected 91/1000 articles\n",
            "Collected 92/1000 articles\n",
            "Collected 93/1000 articles\n",
            "Collected 94/1000 articles\n",
            "Collected 95/1000 articles\n",
            "Collected 96/1000 articles\n",
            "Collected 97/1000 articles\n",
            "Collected 98/1000 articles\n",
            "Collected 99/1000 articles\n",
            "Collected 100/1000 articles\n",
            "Collected 101/1000 articles\n",
            "Collected 102/1000 articles\n",
            "Collected 103/1000 articles\n",
            "Collected 104/1000 articles\n",
            "Collected 105/1000 articles\n",
            "Collected 106/1000 articles\n",
            "Collected 107/1000 articles\n",
            "Collected 108/1000 articles\n",
            "Collected 109/1000 articles\n",
            "Collected 110/1000 articles\n",
            "Collected 111/1000 articles\n",
            "Collected 112/1000 articles\n",
            "Collected 113/1000 articles\n",
            "Collected 114/1000 articles\n",
            "Collected 115/1000 articles\n",
            "Collected 116/1000 articles\n",
            "Collected 117/1000 articles\n",
            "Collected 118/1000 articles\n",
            "Collected 119/1000 articles\n",
            "Collected 120/1000 articles\n",
            "Collected 121/1000 articles\n",
            "Collected 122/1000 articles\n",
            "Collected 123/1000 articles\n",
            "Collected 124/1000 articles\n",
            "Collected 125/1000 articles\n",
            "Collected 126/1000 articles\n",
            "Collected 127/1000 articles\n",
            "Collected 128/1000 articles\n",
            "Collected 129/1000 articles\n",
            "Collected 130/1000 articles\n",
            "Collected 131/1000 articles\n",
            "Collected 132/1000 articles\n",
            "Collected 133/1000 articles\n",
            "Collected 134/1000 articles\n",
            "Collected 135/1000 articles\n",
            "Collected 136/1000 articles\n",
            "Collected 137/1000 articles\n",
            "Collected 138/1000 articles\n",
            "Collected 139/1000 articles\n",
            "Collected 140/1000 articles\n",
            "Collected 141/1000 articles\n",
            "Collected 142/1000 articles\n",
            "Collected 143/1000 articles\n",
            "Collected 144/1000 articles\n",
            "Collected 145/1000 articles\n",
            "Collected 146/1000 articles\n",
            "Collected 147/1000 articles\n",
            "Collected 148/1000 articles\n",
            "Collected 149/1000 articles\n",
            "Collected 150/1000 articles\n",
            "Collected 151/1000 articles\n",
            "Collected 152/1000 articles\n",
            "Collected 153/1000 articles\n",
            "Collected 154/1000 articles\n",
            "Collected 155/1000 articles\n",
            "Collected 156/1000 articles\n",
            "Collected 157/1000 articles\n",
            "Collected 158/1000 articles\n",
            "Collected 159/1000 articles\n",
            "Collected 160/1000 articles\n",
            "Collected 161/1000 articles\n",
            "Collected 162/1000 articles\n",
            "Collected 163/1000 articles\n",
            "Collected 164/1000 articles\n",
            "Collected 165/1000 articles\n",
            "Collected 166/1000 articles\n",
            "Collected 167/1000 articles\n",
            "Collected 168/1000 articles\n",
            "Collected 169/1000 articles\n",
            "Collected 170/1000 articles\n",
            "Collected 171/1000 articles\n",
            "Collected 172/1000 articles\n",
            "Collected 173/1000 articles\n",
            "Collected 174/1000 articles\n",
            "Collected 175/1000 articles\n",
            "Collected 176/1000 articles\n",
            "Collected 177/1000 articles\n",
            "Collected 178/1000 articles\n",
            "Collected 179/1000 articles\n",
            "Collected 180/1000 articles\n",
            "Collected 181/1000 articles\n",
            "Collected 182/1000 articles\n",
            "Collected 183/1000 articles\n",
            "Collected 184/1000 articles\n",
            "Collected 185/1000 articles\n",
            "Collected 186/1000 articles\n",
            "Collected 187/1000 articles\n",
            "Collected 188/1000 articles\n",
            "Collected 189/1000 articles\n",
            "Collected 190/1000 articles\n",
            "Collected 191/1000 articles\n",
            "Collected 192/1000 articles\n",
            "Collected 193/1000 articles\n",
            "Collected 194/1000 articles\n",
            "Collected 195/1000 articles\n",
            "Collected 196/1000 articles\n",
            "Collected 197/1000 articles\n",
            "Collected 198/1000 articles\n",
            "Collected 199/1000 articles\n",
            "Collected 200/1000 articles\n",
            "Collected 201/1000 articles\n",
            "Collected 202/1000 articles\n",
            "Collected 203/1000 articles\n",
            "Collected 204/1000 articles\n",
            "Collected 205/1000 articles\n",
            "Collected 206/1000 articles\n",
            "Collected 207/1000 articles\n",
            "Collected 208/1000 articles\n",
            "Collected 209/1000 articles\n",
            "Collected 210/1000 articles\n",
            "Collected 211/1000 articles\n",
            "Collected 212/1000 articles\n",
            "Collected 213/1000 articles\n",
            "Collected 214/1000 articles\n",
            "Collected 215/1000 articles\n",
            "Collected 216/1000 articles\n",
            "Collected 217/1000 articles\n",
            "Collected 218/1000 articles\n",
            "Collected 219/1000 articles\n",
            "Collected 220/1000 articles\n",
            "Collected 221/1000 articles\n",
            "Collected 222/1000 articles\n",
            "Collected 223/1000 articles\n",
            "Collected 224/1000 articles\n",
            "Collected 225/1000 articles\n",
            "Collected 226/1000 articles\n",
            "Collected 227/1000 articles\n",
            "Collected 228/1000 articles\n",
            "Collected 229/1000 articles\n",
            "Collected 230/1000 articles\n",
            "Collected 231/1000 articles\n",
            "Collected 232/1000 articles\n",
            "Collected 233/1000 articles\n",
            "Collected 234/1000 articles\n",
            "Collected 235/1000 articles\n",
            "Collected 236/1000 articles\n",
            "Collected 237/1000 articles\n",
            "Collected 238/1000 articles\n",
            "Collected 239/1000 articles\n",
            "Collected 240/1000 articles\n",
            "Collected 241/1000 articles\n",
            "Collected 242/1000 articles\n",
            "Collected 243/1000 articles\n",
            "Collected 244/1000 articles\n",
            "Collected 245/1000 articles\n",
            "Collected 246/1000 articles\n",
            "Collected 247/1000 articles\n",
            "Collected 248/1000 articles\n",
            "Collected 249/1000 articles\n",
            "Collected 250/1000 articles\n",
            "Collected 251/1000 articles\n",
            "Collected 252/1000 articles\n",
            "Collected 253/1000 articles\n",
            "Collected 254/1000 articles\n",
            "Collected 255/1000 articles\n",
            "Collected 256/1000 articles\n",
            "Collected 257/1000 articles\n",
            "Collected 258/1000 articles\n",
            "Collected 259/1000 articles\n",
            "Collected 260/1000 articles\n",
            "Collected 261/1000 articles\n",
            "Collected 262/1000 articles\n",
            "Collected 263/1000 articles\n",
            "Collected 264/1000 articles\n",
            "Collected 265/1000 articles\n",
            "Collected 266/1000 articles\n",
            "Collected 267/1000 articles\n",
            "Collected 268/1000 articles\n",
            "Collected 269/1000 articles\n",
            "Collected 270/1000 articles\n",
            "Collected 271/1000 articles\n",
            "Collected 272/1000 articles\n",
            "Collected 273/1000 articles\n",
            "Collected 274/1000 articles\n",
            "Collected 275/1000 articles\n",
            "Collected 276/1000 articles\n",
            "Collected 277/1000 articles\n",
            "Collected 278/1000 articles\n",
            "Collected 279/1000 articles\n",
            "Collected 280/1000 articles\n",
            "Collected 281/1000 articles\n",
            "Collected 282/1000 articles\n",
            "Collected 283/1000 articles\n",
            "Collected 284/1000 articles\n",
            "Collected 285/1000 articles\n",
            "Collected 286/1000 articles\n",
            "Collected 287/1000 articles\n",
            "Collected 288/1000 articles\n",
            "Collected 289/1000 articles\n",
            "Collected 290/1000 articles\n",
            "Collected 291/1000 articles\n",
            "Collected 292/1000 articles\n",
            "Collected 293/1000 articles\n",
            "Collected 294/1000 articles\n",
            "Collected 295/1000 articles\n",
            "Collected 296/1000 articles\n",
            "Collected 297/1000 articles\n",
            "Collected 298/1000 articles\n",
            "Collected 299/1000 articles\n",
            "Collected 300/1000 articles\n",
            "Collected 301/1000 articles\n",
            "Collected 302/1000 articles\n",
            "Collected 303/1000 articles\n",
            "Collected 304/1000 articles\n",
            "Collected 305/1000 articles\n",
            "Collected 306/1000 articles\n",
            "Collected 307/1000 articles\n",
            "Collected 308/1000 articles\n",
            "Collected 309/1000 articles\n",
            "Collected 310/1000 articles\n",
            "Collected 311/1000 articles\n",
            "Collected 312/1000 articles\n",
            "Collected 313/1000 articles\n",
            "Collected 314/1000 articles\n",
            "Collected 315/1000 articles\n",
            "Collected 316/1000 articles\n",
            "Collected 317/1000 articles\n",
            "Collected 318/1000 articles\n",
            "Collected 319/1000 articles\n",
            "Collected 320/1000 articles\n",
            "Collected 321/1000 articles\n",
            "Collected 322/1000 articles\n",
            "Collected 323/1000 articles\n",
            "Collected 324/1000 articles\n",
            "Collected 325/1000 articles\n",
            "Collected 326/1000 articles\n",
            "Collected 327/1000 articles\n",
            "Collected 328/1000 articles\n",
            "Collected 329/1000 articles\n",
            "Collected 330/1000 articles\n",
            "Collected 331/1000 articles\n",
            "Collected 332/1000 articles\n",
            "Collected 333/1000 articles\n",
            "Collected 334/1000 articles\n",
            "Collected 335/1000 articles\n",
            "Collected 336/1000 articles\n",
            "Collected 337/1000 articles\n",
            "Collected 338/1000 articles\n",
            "Collected 339/1000 articles\n",
            "Collected 340/1000 articles\n",
            "Collected 341/1000 articles\n",
            "Collected 342/1000 articles\n",
            "Collected 343/1000 articles\n",
            "Collected 344/1000 articles\n",
            "Collected 345/1000 articles\n",
            "Collected 346/1000 articles\n",
            "Collected 347/1000 articles\n",
            "Collected 348/1000 articles\n",
            "Collected 349/1000 articles\n",
            "Collected 350/1000 articles\n",
            "Collected 351/1000 articles\n",
            "Collected 352/1000 articles\n",
            "Collected 353/1000 articles\n",
            "Collected 354/1000 articles\n",
            "Collected 355/1000 articles\n",
            "Collected 356/1000 articles\n",
            "Collected 357/1000 articles\n",
            "Collected 358/1000 articles\n",
            "Collected 359/1000 articles\n",
            "Collected 360/1000 articles\n",
            "Collected 361/1000 articles\n",
            "Collected 362/1000 articles\n",
            "Collected 363/1000 articles\n",
            "Collected 364/1000 articles\n",
            "Collected 365/1000 articles\n",
            "Collected 366/1000 articles\n",
            "Collected 367/1000 articles\n",
            "Collected 368/1000 articles\n",
            "Collected 369/1000 articles\n",
            "Collected 370/1000 articles\n",
            "Collected 371/1000 articles\n",
            "Collected 372/1000 articles\n",
            "Collected 373/1000 articles\n",
            "Collected 374/1000 articles\n",
            "Collected 375/1000 articles\n",
            "Collected 376/1000 articles\n",
            "Collected 377/1000 articles\n",
            "Collected 378/1000 articles\n",
            "Collected 379/1000 articles\n",
            "Collected 380/1000 articles\n",
            "Collected 381/1000 articles\n",
            "Collected 382/1000 articles\n",
            "Collected 383/1000 articles\n",
            "Collected 384/1000 articles\n",
            "Collected 385/1000 articles\n",
            "Collected 386/1000 articles\n",
            "Collected 387/1000 articles\n",
            "Collected 388/1000 articles\n",
            "Collected 389/1000 articles\n",
            "Collected 390/1000 articles\n",
            "Collected 391/1000 articles\n",
            "Collected 392/1000 articles\n",
            "Collected 393/1000 articles\n",
            "Collected 394/1000 articles\n",
            "Collected 395/1000 articles\n",
            "Collected 396/1000 articles\n",
            "Collected 397/1000 articles\n",
            "Collected 398/1000 articles\n",
            "Collected 399/1000 articles\n",
            "Collected 400/1000 articles\n",
            "Collected 401/1000 articles\n",
            "Collected 402/1000 articles\n",
            "Collected 403/1000 articles\n",
            "Collected 404/1000 articles\n",
            "Collected 405/1000 articles\n",
            "Collected 406/1000 articles\n",
            "Collected 407/1000 articles\n",
            "Collected 408/1000 articles\n",
            "Collected 409/1000 articles\n",
            "Collected 410/1000 articles\n",
            "Collected 411/1000 articles\n",
            "Collected 412/1000 articles\n",
            "Collected 413/1000 articles\n",
            "Collected 414/1000 articles\n",
            "Collected 415/1000 articles\n",
            "Collected 416/1000 articles\n",
            "Collected 417/1000 articles\n",
            "Collected 418/1000 articles\n",
            "Collected 419/1000 articles\n",
            "Collected 420/1000 articles\n",
            "Collected 421/1000 articles\n",
            "Collected 422/1000 articles\n",
            "Collected 423/1000 articles\n",
            "Collected 424/1000 articles\n",
            "Collected 425/1000 articles\n",
            "Collected 426/1000 articles\n",
            "Collected 427/1000 articles\n",
            "Collected 428/1000 articles\n",
            "Collected 429/1000 articles\n",
            "Collected 430/1000 articles\n",
            "Collected 431/1000 articles\n",
            "Collected 432/1000 articles\n",
            "Collected 433/1000 articles\n",
            "Collected 434/1000 articles\n",
            "Collected 435/1000 articles\n",
            "Collected 436/1000 articles\n",
            "Collected 437/1000 articles\n",
            "Collected 438/1000 articles\n",
            "Collected 439/1000 articles\n",
            "Collected 440/1000 articles\n",
            "Collected 441/1000 articles\n",
            "Collected 442/1000 articles\n",
            "Collected 443/1000 articles\n",
            "Collected 444/1000 articles\n",
            "Collected 445/1000 articles\n",
            "Collected 446/1000 articles\n",
            "Collected 447/1000 articles\n",
            "Collected 448/1000 articles\n",
            "Collected 449/1000 articles\n",
            "Collected 450/1000 articles\n",
            "Collected 451/1000 articles\n",
            "Collected 452/1000 articles\n",
            "Collected 453/1000 articles\n",
            "Collected 454/1000 articles\n",
            "Collected 455/1000 articles\n",
            "Collected 456/1000 articles\n",
            "Collected 457/1000 articles\n",
            "Collected 458/1000 articles\n",
            "Collected 459/1000 articles\n",
            "Collected 460/1000 articles\n",
            "Collected 461/1000 articles\n",
            "Collected 462/1000 articles\n",
            "Collected 463/1000 articles\n",
            "Collected 464/1000 articles\n",
            "Collected 465/1000 articles\n",
            "Collected 466/1000 articles\n",
            "Collected 467/1000 articles\n",
            "Collected 468/1000 articles\n",
            "Collected 469/1000 articles\n",
            "Collected 470/1000 articles\n",
            "Collected 471/1000 articles\n",
            "Collected 472/1000 articles\n",
            "Collected 473/1000 articles\n",
            "Collected 474/1000 articles\n",
            "Collected 475/1000 articles\n",
            "Collected 476/1000 articles\n",
            "Collected 477/1000 articles\n",
            "Collected 478/1000 articles\n",
            "Collected 479/1000 articles\n",
            "Collected 480/1000 articles\n",
            "Collected 481/1000 articles\n",
            "Collected 482/1000 articles\n",
            "Collected 483/1000 articles\n",
            "Collected 484/1000 articles\n",
            "Collected 485/1000 articles\n",
            "Collected 486/1000 articles\n",
            "Collected 487/1000 articles\n",
            "Collected 488/1000 articles\n",
            "Collected 489/1000 articles\n",
            "Collected 490/1000 articles\n",
            "Collected 491/1000 articles\n",
            "Collected 492/1000 articles\n",
            "Collected 493/1000 articles\n",
            "Collected 494/1000 articles\n",
            "Collected 495/1000 articles\n",
            "Collected 496/1000 articles\n",
            "Collected 497/1000 articles\n",
            "Collected 498/1000 articles\n",
            "Collected 499/1000 articles\n",
            "Collected 500/1000 articles\n",
            "Collected 501/1000 articles\n",
            "Collected 502/1000 articles\n",
            "Collected 503/1000 articles\n",
            "Collected 504/1000 articles\n",
            "Collected 505/1000 articles\n",
            "Collected 506/1000 articles\n",
            "Collected 507/1000 articles\n",
            "Collected 508/1000 articles\n",
            "Collected 509/1000 articles\n",
            "Collected 510/1000 articles\n",
            "Collected 511/1000 articles\n",
            "Collected 512/1000 articles\n",
            "Collected 513/1000 articles\n",
            "Collected 514/1000 articles\n",
            "Collected 515/1000 articles\n",
            "Collected 516/1000 articles\n",
            "Collected 517/1000 articles\n",
            "Collected 518/1000 articles\n",
            "Collected 519/1000 articles\n",
            "Collected 520/1000 articles\n",
            "Collected 521/1000 articles\n",
            "Collected 522/1000 articles\n",
            "Collected 523/1000 articles\n",
            "Collected 524/1000 articles\n",
            "Collected 525/1000 articles\n",
            "Collected 526/1000 articles\n",
            "Collected 527/1000 articles\n",
            "Collected 528/1000 articles\n",
            "Collected 529/1000 articles\n",
            "Collected 530/1000 articles\n",
            "Collected 531/1000 articles\n",
            "Collected 532/1000 articles\n",
            "Collected 533/1000 articles\n",
            "Collected 534/1000 articles\n",
            "Collected 535/1000 articles\n",
            "Collected 536/1000 articles\n",
            "Collected 537/1000 articles\n",
            "Collected 538/1000 articles\n",
            "Collected 539/1000 articles\n",
            "Collected 540/1000 articles\n",
            "Collected 541/1000 articles\n",
            "Collected 542/1000 articles\n",
            "Collected 543/1000 articles\n",
            "Collected 544/1000 articles\n",
            "Collected 545/1000 articles\n",
            "Collected 546/1000 articles\n",
            "Collected 547/1000 articles\n",
            "Collected 548/1000 articles\n",
            "Collected 549/1000 articles\n",
            "Collected 550/1000 articles\n",
            "Collected 551/1000 articles\n",
            "Collected 552/1000 articles\n",
            "Collected 553/1000 articles\n",
            "Collected 554/1000 articles\n",
            "Collected 555/1000 articles\n",
            "Collected 556/1000 articles\n",
            "Collected 557/1000 articles\n",
            "Collected 558/1000 articles\n",
            "Collected 559/1000 articles\n",
            "Collected 560/1000 articles\n",
            "Collected 561/1000 articles\n",
            "Collected 562/1000 articles\n",
            "Collected 563/1000 articles\n",
            "Collected 564/1000 articles\n",
            "Collected 565/1000 articles\n",
            "Collected 566/1000 articles\n",
            "Collected 567/1000 articles\n",
            "Collected 568/1000 articles\n",
            "Collected 569/1000 articles\n",
            "Collected 570/1000 articles\n",
            "Collected 571/1000 articles\n",
            "Collected 572/1000 articles\n",
            "Collected 573/1000 articles\n",
            "Collected 574/1000 articles\n",
            "Collected 575/1000 articles\n",
            "Collected 576/1000 articles\n",
            "Collected 577/1000 articles\n",
            "Collected 578/1000 articles\n",
            "Collected 579/1000 articles\n",
            "Collected 580/1000 articles\n",
            "Collected 581/1000 articles\n",
            "Collected 582/1000 articles\n",
            "Collected 583/1000 articles\n",
            "Collected 584/1000 articles\n",
            "Collected 585/1000 articles\n",
            "Collected 586/1000 articles\n",
            "Collected 587/1000 articles\n",
            "Collected 588/1000 articles\n",
            "Collected 589/1000 articles\n",
            "Collected 590/1000 articles\n",
            "Collected 591/1000 articles\n",
            "Collected 592/1000 articles\n",
            "Collected 593/1000 articles\n",
            "Collected 594/1000 articles\n",
            "Collected 595/1000 articles\n",
            "Collected 596/1000 articles\n",
            "Collected 597/1000 articles\n",
            "Collected 598/1000 articles\n",
            "Collected 599/1000 articles\n",
            "Collected 600/1000 articles\n",
            "Collected 601/1000 articles\n",
            "Collected 602/1000 articles\n",
            "Collected 603/1000 articles\n",
            "Collected 604/1000 articles\n",
            "Collected 605/1000 articles\n",
            "Collected 606/1000 articles\n",
            "Collected 607/1000 articles\n",
            "Collected 608/1000 articles\n",
            "Collected 609/1000 articles\n",
            "Collected 610/1000 articles\n",
            "Collected 611/1000 articles\n",
            "Collected 612/1000 articles\n",
            "Collected 613/1000 articles\n",
            "Collected 614/1000 articles\n",
            "Collected 615/1000 articles\n",
            "Collected 616/1000 articles\n",
            "Collected 617/1000 articles\n",
            "Collected 618/1000 articles\n",
            "Collected 619/1000 articles\n",
            "Collected 620/1000 articles\n",
            "Collected 621/1000 articles\n",
            "Collected 622/1000 articles\n",
            "Collected 623/1000 articles\n",
            "Collected 624/1000 articles\n",
            "Collected 625/1000 articles\n",
            "Collected 626/1000 articles\n",
            "Collected 627/1000 articles\n",
            "Collected 628/1000 articles\n",
            "Collected 629/1000 articles\n",
            "Collected 630/1000 articles\n",
            "Collected 631/1000 articles\n",
            "Collected 632/1000 articles\n",
            "Collected 633/1000 articles\n",
            "Collected 634/1000 articles\n",
            "Collected 635/1000 articles\n",
            "Collected 636/1000 articles\n",
            "Collected 637/1000 articles\n",
            "Collected 638/1000 articles\n",
            "Collected 639/1000 articles\n",
            "Collected 640/1000 articles\n",
            "Collected 641/1000 articles\n",
            "Collected 642/1000 articles\n",
            "Collected 643/1000 articles\n",
            "Collected 644/1000 articles\n",
            "Collected 645/1000 articles\n",
            "Collected 646/1000 articles\n",
            "Collected 647/1000 articles\n",
            "Collected 648/1000 articles\n",
            "Collected 649/1000 articles\n",
            "Collected 650/1000 articles\n",
            "Collected 651/1000 articles\n",
            "Collected 652/1000 articles\n",
            "Collected 653/1000 articles\n",
            "Collected 654/1000 articles\n",
            "Collected 655/1000 articles\n",
            "Collected 656/1000 articles\n",
            "Collected 657/1000 articles\n",
            "Collected 658/1000 articles\n",
            "Collected 659/1000 articles\n",
            "Collected 660/1000 articles\n",
            "Collected 661/1000 articles\n",
            "Collected 662/1000 articles\n",
            "Collected 663/1000 articles\n",
            "Collected 664/1000 articles\n",
            "Collected 665/1000 articles\n",
            "Collected 666/1000 articles\n",
            "Collected 667/1000 articles\n",
            "Collected 668/1000 articles\n",
            "Collected 669/1000 articles\n",
            "Collected 670/1000 articles\n",
            "Collected 671/1000 articles\n",
            "Collected 672/1000 articles\n",
            "Collected 673/1000 articles\n",
            "Collected 674/1000 articles\n",
            "Collected 675/1000 articles\n",
            "Collected 676/1000 articles\n",
            "Collected 677/1000 articles\n",
            "Collected 678/1000 articles\n",
            "Collected 679/1000 articles\n",
            "Collected 680/1000 articles\n",
            "Collected 681/1000 articles\n",
            "Collected 682/1000 articles\n",
            "Collected 683/1000 articles\n",
            "Collected 684/1000 articles\n",
            "Collected 685/1000 articles\n",
            "Collected 686/1000 articles\n",
            "Collected 687/1000 articles\n",
            "Collected 688/1000 articles\n",
            "Collected 689/1000 articles\n",
            "Collected 690/1000 articles\n",
            "Collected 691/1000 articles\n",
            "Collected 692/1000 articles\n",
            "Collected 693/1000 articles\n",
            "Collected 694/1000 articles\n",
            "Collected 695/1000 articles\n",
            "Collected 696/1000 articles\n",
            "Collected 697/1000 articles\n",
            "Collected 698/1000 articles\n",
            "Collected 699/1000 articles\n",
            "Collected 700/1000 articles\n",
            "Collected 701/1000 articles\n",
            "Collected 702/1000 articles\n",
            "Collected 703/1000 articles\n",
            "Collected 704/1000 articles\n",
            "Collected 705/1000 articles\n",
            "Collected 706/1000 articles\n",
            "Collected 707/1000 articles\n",
            "Collected 708/1000 articles\n",
            "Collected 709/1000 articles\n",
            "Collected 710/1000 articles\n",
            "Collected 711/1000 articles\n",
            "Collected 712/1000 articles\n",
            "Collected 713/1000 articles\n",
            "Collected 714/1000 articles\n",
            "Collected 715/1000 articles\n",
            "Collected 716/1000 articles\n",
            "Collected 717/1000 articles\n",
            "Collected 718/1000 articles\n",
            "Collected 719/1000 articles\n",
            "Collected 720/1000 articles\n",
            "Collected 721/1000 articles\n",
            "Collected 722/1000 articles\n",
            "Collected 723/1000 articles\n",
            "Collected 724/1000 articles\n",
            "Collected 725/1000 articles\n",
            "Collected 726/1000 articles\n",
            "Collected 727/1000 articles\n",
            "Collected 728/1000 articles\n",
            "Collected 729/1000 articles\n",
            "Collected 730/1000 articles\n",
            "Collected 731/1000 articles\n",
            "Collected 732/1000 articles\n",
            "Collected 733/1000 articles\n",
            "Collected 734/1000 articles\n",
            "Collected 735/1000 articles\n",
            "Collected 736/1000 articles\n",
            "Collected 737/1000 articles\n",
            "Collected 738/1000 articles\n",
            "Collected 739/1000 articles\n",
            "Collected 740/1000 articles\n",
            "Collected 741/1000 articles\n",
            "Collected 742/1000 articles\n",
            "Collected 743/1000 articles\n",
            "Collected 744/1000 articles\n",
            "Collected 745/1000 articles\n",
            "Collected 746/1000 articles\n",
            "Collected 747/1000 articles\n",
            "Collected 748/1000 articles\n",
            "Collected 749/1000 articles\n",
            "Collected 750/1000 articles\n",
            "Collected 751/1000 articles\n",
            "Collected 752/1000 articles\n",
            "Collected 753/1000 articles\n",
            "Collected 754/1000 articles\n",
            "Collected 755/1000 articles\n",
            "Collected 756/1000 articles\n",
            "Collected 757/1000 articles\n",
            "Collected 758/1000 articles\n",
            "Collected 759/1000 articles\n",
            "Collected 760/1000 articles\n",
            "Collected 761/1000 articles\n",
            "Collected 762/1000 articles\n",
            "Collected 763/1000 articles\n",
            "Collected 764/1000 articles\n",
            "Collected 765/1000 articles\n",
            "Collected 766/1000 articles\n",
            "Collected 767/1000 articles\n",
            "Collected 768/1000 articles\n",
            "Collected 769/1000 articles\n",
            "Collected 770/1000 articles\n",
            "Collected 771/1000 articles\n",
            "Collected 772/1000 articles\n",
            "Collected 773/1000 articles\n",
            "Collected 774/1000 articles\n",
            "Collected 775/1000 articles\n",
            "Collected 776/1000 articles\n",
            "Collected 777/1000 articles\n",
            "Collected 778/1000 articles\n",
            "Collected 779/1000 articles\n",
            "Collected 780/1000 articles\n",
            "Collected 781/1000 articles\n",
            "Collected 782/1000 articles\n",
            "Collected 783/1000 articles\n",
            "Collected 784/1000 articles\n",
            "Collected 785/1000 articles\n",
            "Collected 786/1000 articles\n",
            "Collected 787/1000 articles\n",
            "Collected 788/1000 articles\n",
            "Collected 789/1000 articles\n",
            "Collected 790/1000 articles\n",
            "Collected 791/1000 articles\n",
            "Collected 792/1000 articles\n",
            "Collected 793/1000 articles\n",
            "Collected 794/1000 articles\n",
            "Collected 795/1000 articles\n",
            "Collected 796/1000 articles\n",
            "Collected 797/1000 articles\n",
            "Collected 798/1000 articles\n",
            "Collected 799/1000 articles\n",
            "Collected 800/1000 articles\n",
            "Collected 801/1000 articles\n",
            "Collected 802/1000 articles\n",
            "Collected 803/1000 articles\n",
            "Collected 804/1000 articles\n",
            "Collected 805/1000 articles\n",
            "Collected 806/1000 articles\n",
            "Collected 807/1000 articles\n",
            "Collected 808/1000 articles\n",
            "Collected 809/1000 articles\n",
            "Collected 810/1000 articles\n",
            "Collected 811/1000 articles\n",
            "Collected 812/1000 articles\n",
            "Collected 813/1000 articles\n",
            "Collected 814/1000 articles\n",
            "Collected 815/1000 articles\n",
            "Collected 816/1000 articles\n",
            "Collected 817/1000 articles\n",
            "Collected 818/1000 articles\n",
            "Collected 819/1000 articles\n",
            "Collected 820/1000 articles\n",
            "Collected 821/1000 articles\n",
            "Collected 822/1000 articles\n",
            "Collected 823/1000 articles\n",
            "Collected 824/1000 articles\n",
            "Collected 825/1000 articles\n",
            "Collected 826/1000 articles\n",
            "Collected 827/1000 articles\n",
            "Collected 828/1000 articles\n",
            "Collected 829/1000 articles\n",
            "Collected 830/1000 articles\n",
            "Collected 831/1000 articles\n",
            "Collected 832/1000 articles\n",
            "Collected 833/1000 articles\n",
            "Collected 834/1000 articles\n",
            "Collected 835/1000 articles\n",
            "Collected 836/1000 articles\n",
            "Collected 837/1000 articles\n",
            "Collected 838/1000 articles\n",
            "Collected 839/1000 articles\n",
            "Collected 840/1000 articles\n",
            "Collected 841/1000 articles\n",
            "Collected 842/1000 articles\n",
            "Collected 843/1000 articles\n",
            "Collected 844/1000 articles\n",
            "Collected 845/1000 articles\n",
            "Collected 846/1000 articles\n",
            "Collected 847/1000 articles\n",
            "Collected 848/1000 articles\n",
            "Collected 849/1000 articles\n",
            "Collected 850/1000 articles\n",
            "Collected 851/1000 articles\n",
            "Collected 852/1000 articles\n",
            "Collected 853/1000 articles\n",
            "Collected 854/1000 articles\n",
            "Collected 855/1000 articles\n",
            "Collected 856/1000 articles\n",
            "Collected 857/1000 articles\n",
            "Collected 858/1000 articles\n",
            "Collected 859/1000 articles\n",
            "Collected 860/1000 articles\n",
            "Collected 861/1000 articles\n",
            "Collected 862/1000 articles\n",
            "Collected 863/1000 articles\n",
            "Collected 864/1000 articles\n",
            "Collected 865/1000 articles\n",
            "Collected 866/1000 articles\n",
            "Collected 867/1000 articles\n",
            "Collected 868/1000 articles\n",
            "Collected 869/1000 articles\n",
            "Collected 870/1000 articles\n",
            "Collected 871/1000 articles\n",
            "Collected 872/1000 articles\n",
            "Collected 873/1000 articles\n",
            "Collected 874/1000 articles\n",
            "Collected 875/1000 articles\n",
            "Collected 876/1000 articles\n",
            "Collected 877/1000 articles\n",
            "Collected 878/1000 articles\n",
            "Collected 879/1000 articles\n",
            "Collected 880/1000 articles\n",
            "Collected 881/1000 articles\n",
            "Collected 882/1000 articles\n",
            "Collected 883/1000 articles\n",
            "Collected 884/1000 articles\n",
            "Collected 885/1000 articles\n",
            "Collected 886/1000 articles\n",
            "Collected 887/1000 articles\n",
            "Collected 888/1000 articles\n",
            "Collected 889/1000 articles\n",
            "Collected 890/1000 articles\n",
            "Collected 891/1000 articles\n",
            "Collected 892/1000 articles\n",
            "Collected 893/1000 articles\n",
            "Collected 894/1000 articles\n",
            "Collected 895/1000 articles\n",
            "Collected 896/1000 articles\n",
            "Collected 897/1000 articles\n",
            "Collected 898/1000 articles\n",
            "Collected 899/1000 articles\n",
            "Collected 900/1000 articles\n",
            "Collected 901/1000 articles\n",
            "Collected 902/1000 articles\n",
            "Collected 903/1000 articles\n",
            "Collected 904/1000 articles\n",
            "Collected 905/1000 articles\n",
            "Collected 906/1000 articles\n",
            "Collected 907/1000 articles\n",
            "Collected 908/1000 articles\n",
            "Collected 909/1000 articles\n",
            "Collected 910/1000 articles\n",
            "Collected 911/1000 articles\n",
            "Collected 912/1000 articles\n",
            "Collected 913/1000 articles\n",
            "Collected 914/1000 articles\n",
            "Collected 915/1000 articles\n",
            "Collected 916/1000 articles\n",
            "Collected 917/1000 articles\n",
            "Collected 918/1000 articles\n",
            "Collected 919/1000 articles\n",
            "Collected 920/1000 articles\n",
            "Collected 921/1000 articles\n",
            "Collected 922/1000 articles\n",
            "Collected 923/1000 articles\n",
            "Collected 924/1000 articles\n",
            "Collected 925/1000 articles\n",
            "Collected 926/1000 articles\n",
            "Collected 927/1000 articles\n",
            "Collected 928/1000 articles\n",
            "Collected 929/1000 articles\n",
            "Collected 930/1000 articles\n",
            "Collected 931/1000 articles\n",
            "Collected 932/1000 articles\n",
            "Collected 933/1000 articles\n",
            "Collected 934/1000 articles\n",
            "Collected 935/1000 articles\n",
            "Collected 936/1000 articles\n",
            "Collected 937/1000 articles\n",
            "Collected 938/1000 articles\n",
            "Collected 939/1000 articles\n",
            "Collected 940/1000 articles\n",
            "Collected 941/1000 articles\n",
            "Collected 942/1000 articles\n",
            "Collected 943/1000 articles\n",
            "Collected 944/1000 articles\n",
            "Collected 945/1000 articles\n",
            "Collected 946/1000 articles\n",
            "Collected 947/1000 articles\n",
            "Collected 948/1000 articles\n",
            "Collected 949/1000 articles\n",
            "Collected 950/1000 articles\n",
            "Collected 951/1000 articles\n",
            "Collected 952/1000 articles\n",
            "Collected 953/1000 articles\n",
            "Collected 954/1000 articles\n",
            "Collected 955/1000 articles\n",
            "Collected 956/1000 articles\n",
            "Collected 957/1000 articles\n",
            "Collected 958/1000 articles\n",
            "Collected 959/1000 articles\n",
            "Collected 960/1000 articles\n",
            "Collected 961/1000 articles\n",
            "Collected 962/1000 articles\n",
            "Collected 963/1000 articles\n",
            "Collected 964/1000 articles\n",
            "Collected 965/1000 articles\n",
            "Collected 966/1000 articles\n",
            "Collected 967/1000 articles\n",
            "Collected 968/1000 articles\n",
            "Collected 969/1000 articles\n",
            "Collected 970/1000 articles\n",
            "Collected 971/1000 articles\n",
            "Collected 972/1000 articles\n",
            "Collected 973/1000 articles\n",
            "Collected 974/1000 articles\n",
            "Collected 975/1000 articles\n",
            "Collected 976/1000 articles\n",
            "Collected 977/1000 articles\n",
            "Collected 978/1000 articles\n",
            "Collected 979/1000 articles\n",
            "Collected 980/1000 articles\n",
            "Collected 981/1000 articles\n",
            "Collected 982/1000 articles\n",
            "Collected 983/1000 articles\n",
            "Collected 984/1000 articles\n",
            "Collected 985/1000 articles\n",
            "Collected 986/1000 articles\n",
            "Collected 987/1000 articles\n",
            "Collected 988/1000 articles\n",
            "Collected 989/1000 articles\n",
            "Collected 990/1000 articles\n",
            "Collected 991/1000 articles\n",
            "Collected 992/1000 articles\n",
            "Collected 993/1000 articles\n",
            "Collected 994/1000 articles\n",
            "Collected 995/1000 articles\n",
            "Collected 996/1000 articles\n",
            "Collected 997/1000 articles\n",
            "Collected 998/1000 articles\n",
            "Collected 999/1000 articles\n",
            "Collected 1000/1000 articles\n",
            "Saving data...\n",
            "Data saved to ai_news_articles.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def fetch_acm_articles(keyword, start_year, end_year, num_articles=1000):\n",
        "    base_url = \"https://dl.acm.org/action/doSearch\"\n",
        "\n",
        "    # Initialize an empty list to store article information\n",
        "    articles = []\n",
        "    start = 0  # For pagination\n",
        "\n",
        "    while len(articles) < num_articles:\n",
        "        search_url = f\"{base_url}?AllField={keyword}&startYear={start_year}&endYear={end_year}&pageSize=50&startPage={start}\"\n",
        "\n",
        "        # Fetch search results\n",
        "        response = requests.get(search_url)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Extract article details\n",
        "        results = soup.find_all(\"div\", class_=\"issue-item__content\")\n",
        "        for result in results:\n",
        "            # Safely extract title\n",
        "            title_element = result.find(\"h5\", class_=\"issue-item__title\")\n",
        "            title = title_element.text.strip() if title_element else \"N/A\"\n",
        "\n",
        "            # Safely extract authors\n",
        "            authors_element = result.find(\"span\", class_=\"issue-item__authors\")\n",
        "            authors = authors_element.text.strip() if authors_element else \"N/A\"\n",
        "\n",
        "            # Safely extract venue\n",
        "            venue_element = result.find(\"span\", class_=\"issue-item__venue\")\n",
        "            venue = venue_element.text.strip() if venue_element else \"N/A\"\n",
        "\n",
        "            # Safely extract year\n",
        "            year_element = result.find(\"span\", class_=\"issue-item__year\")\n",
        "            year = year_element.text.strip() if year_element else \"N/A\"\n",
        "\n",
        "            # Safely extract abstract\n",
        "            abstract_element = result.find(\"div\", class_=\"issue-item__abstract\")\n",
        "            abstract = abstract_element.text.strip() if abstract_element else \"N/A\"\n",
        "\n",
        "            articles.append({\n",
        "                \"Title\": title,\n",
        "                \"Authors\": authors,\n",
        "                \"Venue\": venue,\n",
        "                \"Year\": year,\n",
        "                \"Abstract\": abstract\n",
        "            })\n",
        "\n",
        "            # Stop if we've collected enough articles\n",
        "            if len(articles) >= num_articles:\n",
        "                break\n",
        "\n",
        "        # Increment the page for pagination\n",
        "        start += 1\n",
        "\n",
        "        # If no more results are found, break the loop\n",
        "        if not results:\n",
        "            break\n",
        "\n",
        "    return articles\n",
        "\n",
        "# Usage example\n",
        "keyword = \"XYZ\"\n",
        "start_year = 2014\n",
        "end_year = 2024\n",
        "num_articles_to_collect = 1000\n",
        "\n",
        "xyz_articles = fetch_acm_articles(keyword, start_year, end_year, num_articles_to_collect)\n",
        "\n",
        "# Create a DataFrame from the list of articles\n",
        "df = pd.DataFrame(xyz_articles)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_filename = \"xyz_articles.csv\"\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"Saved {len(df)} articles to {csv_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "053XRm8wteGj",
        "outputId": "c7336da0-b3da-4118-fb60-230fc55c38d3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 1000 articles to xyz_articles.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqxGKUC-qHnm",
        "outputId": "ec3b3b86-3533-4d8c-a09c-bc379f7f2346"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.1 in /usr/local/lib/python3.10/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MtKskTzbCLaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6dd948e-b9e7-4b87-b437-4c797480917b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  score       id  \\\n",
            "0  I teach Python courses - here's my collection ...   2975   jii8ex   \n",
            "1  Six months into Python and Data science, my fi...   1723   g5ymoy   \n",
            "2  Modern alternatives to Data Science Libraries ...    208  196jbms   \n",
            "3  If you're a beginner interested in data scienc...    827   xyyj9t   \n",
            "4  If you're a beginner interested in data scienc...    696  12j68f7   \n",
            "5  1 year ago I started building Practice Probs -...    788   zzv4zt   \n",
            "6  Python Data Science December [Completed] - 24 ...    518   zu7vqp   \n",
            "7  78 Python data science practice problems in a ...    776   u77fce   \n",
            "8  Build a Data Science SaaS App with Just Python...    103  173qcwe   \n",
            "9  What features of the Python language predestin...     73   zu8azk   \n",
            "\n",
            "                                                 url       created  \\\n",
            "0      https://marko-knoebl.github.io/slides/#python  1.603731e+09   \n",
            "1                    https://v.redd.it/mlqov8dbicu41  1.587551e+09   \n",
            "2  https://www.reddit.com/r/Python/comments/196jb...  1.705249e+09   \n",
            "3  https://youtube.com/playlist?list=PLvICEeb-TZE...  1.665250e+09   \n",
            "4  https://www.youtube.com/playlist?list=PLvICEeb...  1.681265e+09   \n",
            "5  https://www.reddit.com/r/Python/comments/zzv4z...  1.672497e+09   \n",
            "6  https://www.reddit.com/r/Python/comments/zu7vq...  1.671881e+09   \n",
            "7       https://github.com/practiceprobs/problemsets  1.650381e+09   \n",
            "8  https://www.reddit.com/r/Python/comments/173qc...  1.696854e+09   \n",
            "9  https://www.reddit.com/r/Python/comments/zu8az...  1.671883e+09   \n",
            "\n",
            "   num_comments  \n",
            "0            88  \n",
            "1           139  \n",
            "2            69  \n",
            "3            32  \n",
            "4            24  \n",
            "5            26  \n",
            "6            37  \n",
            "7            22  \n",
            "8            43  \n",
            "9            78  \n"
          ]
        }
      ],
      "source": [
        "# write your answer here\n",
        "\n",
        "import praw\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize the Reddit API client\n",
        "reddit = praw.Reddit(\n",
        "    client_id='H2pzWfXFrWmjPSy63_8z3A',\n",
        "    client_secret='SBHhAkSF7xn8G2miJrwlNsy3PrQWvg',\n",
        "    user_agent='Siva'\n",
        ")\n",
        "# Function to collect data from Reddit\n",
        "def collect_reddit_data(subreddit_name, keyword, limit=100):\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "    posts = subreddit.search(keyword, limit=limit)\n",
        "\n",
        "    data = []\n",
        "    for post in posts:\n",
        "        data.append({\n",
        "            'title': post.title,\n",
        "            'score': post.score,\n",
        "            'id': post.id,\n",
        "            'url': post.url,\n",
        "            'created': post.created_utc,\n",
        "            'num_comments': post.num_comments\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Collect data\n",
        "df_reddit = collect_reddit_data('python', 'data science', 10)\n",
        "print(df_reddit)\n",
        "\n",
        "# Save to a CSV file\n",
        "df_reddit.to_csv('reddit_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I57NXsauCec2"
      },
      "outputs": [],
      "source": [
        "# write your answer here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "sZOhks1dXWEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ],
      "metadata": {
        "id": "eqmHVEwaWhbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Write your response here.\n",
        "Learning Experience: It's been overvelmig for me as webscraping excercise required me to run through many packages and libraries\n",
        "\n",
        "Challenges Encountered: I encountered many errors and reached limit while working with api's.\n",
        "\n",
        "Relevance to Your Field of Study: In my view web scraping is important skill while learning with AI and ML and even for jobs many employers want to scrape data from websites.\n",
        "Overall I want to understand more about webscraping and do some intresting projects\n",
        "'''"
      ],
      "metadata": {
        "id": "akAVJn9YBTQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FBKvD6O_TY6e",
        "E9RqrlwdTfvl",
        "03jb4GZsBkBS",
        "jJDe71iLB616",
        "55W9AMdXCSpV",
        "4ulBZ6yhCi9F",
        "6SmvS7nSfbj8",
        "sZOhks1dXWEe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}